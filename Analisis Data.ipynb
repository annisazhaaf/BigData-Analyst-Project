{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4dca6a-b100-4969-9a2c-2f7360e68286",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0513cc9-7adc-49da-8051-c952c0c6f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download en_core_web_sm\n",
    "!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce201f-c853-4cb5-b3a1-8549ee6ef2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b30e83f-4363-48c5-b262-1b852176cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd00903-16c7-4aaa-94af-d9bed0a7d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Load SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d51117-8cec-44f3-be66-82d879e44d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membaca file CSV\n",
    "df = pd.read_csv('cleaned_ifberita.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208a31c-f0b5-4ae2-bce5-f7c0aeff64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return [(entity.text, entity.label_) for entity in doc.ents]\n",
    "\n",
    "# Menerapkan ekstraksi entitas ke kolom teks\n",
    "df['entities'] = df['Kategori'].apply(extract_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269744d-818d-44ee-aefa-d3f7be5df1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcff63-fc54-45e4-89ed-f36f83a4edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisasi dan vectorization\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# LDA\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Menampilkan topik\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "print_top_words(lda, vectorizer.get_feature_names_out(), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd127d-572d-4f6a-8bd2-7fa98a3b5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi VADER sentiment intensity analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Fungsi untuk mendapatkan sentimen\n",
    "def get_sentiment(text):\n",
    "    return sid.polarity_scores(text)\n",
    "\n",
    "# Menerapkan analisis sentimen\n",
    "df['sentiment'] = df['text'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270dc803-7700-449e-8802-2c18abf249da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan kolom 'date' dalam format datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Mengelompokkan data berdasarkan waktu (misal bulanan) dan menghitung rata-rata sentimen\n",
    "df.set_index('date', inplace=True)\n",
    "monthly_sentiment = df.resample('M').mean()\n",
    "\n",
    "# Visualisasi tren sentimen\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(monthly_sentiment.index, monthly_sentiment['sentiment'].apply(lambda x: x['compound']))\n",
    "plt.title('Monthly Sentiment Trend')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4ded9-9558-41b9-8146-145ab6ff067b",
   "metadata": {},
   "source": [
    "ALGORITMA NLP UNTUK IDENTIFIKASI TOPIK UTAMA BERITA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea9e3fd-579d-421f-b29a-668ed101a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12120f87-5eba-4419-a0b6-6fbb16c9f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=4YGkfAd2iXM (Sentimen Analisis)\n",
    "https://www.youtube.com/watch?v=oMSxmZLhZgs (About NLP Identify Topic)\n",
    "https://www.youtube.com/watch?v=z4DQYprjPSs (Summarize Project Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fc988-5613-479d-a28d-f03692df5f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
